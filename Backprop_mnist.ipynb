{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho - Redes Neurais Artificiais\n",
    "\n",
    "## Método adotado: Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rafael Maia e Luís "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação das bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BP_Model:\n",
    "    maxAcuracia = 0 \n",
    "    def __init__(self, tamEntrada, tamCamadaEscondida, tamSaida, rate=0.1):\n",
    "        self.dEntrada = tamEntrada\n",
    "        self.dCamadaEscondida = tamCamadaEscondida\n",
    "        self.dSaida = tamSaida\n",
    "        self.wInH = np.random.rand(self.dEntrada, self.dCamadaEscondida)*0.2-0.1\n",
    "        self.wOutH = np.random.rand(self.dCamadaEscondida, self.dSaida)*0.2-0.1\n",
    "        self.delta_InH = np.zeros(self.dCamadaEscondida)\n",
    "        self.delta_OutH = np.zeros(self.dSaida)\n",
    "        self.learning_rate = rate\n",
    "        self.custo = 0\n",
    "\n",
    "    def forward(self, sample):\n",
    "        ativCamadaOculta = self.tanh(np.dot(sample, self.wInH))\n",
    "        activCamadaSaida = self.sigmoid(np.dot(ativCamadaOculta, self.wOutH))\n",
    "        return ativCamadaOculta, activCamadaSaida\n",
    "\n",
    "    def auxAcao(self, x, y):\n",
    "        saida = self.forward(x)[1]\n",
    "        return np.sum((np.array(saida) - np.array(y))**2)*0.5, np.array(saida)-np.array(y)\n",
    "\n",
    "    def Acao(self, x, y):\n",
    "        val = 0.\n",
    "        vec = np.zeros(self.dSaida)\n",
    "        for i in range(len(x)):\n",
    "            temp = self.auxAcao(x[i],y[i])\n",
    "            val += temp[0]\n",
    "            vec += temp[1]\n",
    "        return val, vec\n",
    "\n",
    "    def auxBP(self, x, y):\n",
    "        custo, custo_vec = self.auxAcao(x, y)\n",
    "        activHidden, activSaida = self.forward(x)\n",
    "        deltaSaida = custo_vec * activSaida * (1-activSaida)\n",
    "        deltaH = np.dot(self.wOutH, deltaSaida) * (1-activHidden**2)\n",
    "        self.wOutH -= self.learning_rate*deltaSaida*activHidden[:,np.newaxis]\n",
    "        self.wInH -= self.learning_rate * deltaH * np.array(x)[:,np.newaxis]\n",
    "        return self.wOutH, self.wInH, custo\n",
    "\n",
    "    def BP(self, x, y):\n",
    "        self.custo = 0\n",
    "        tam = np.arange(len(x))\n",
    "        np.random.shuffle(tam)\n",
    "        for i in tam[:100]:\n",
    "            wOutH, wInH, cost = self.auxBP(x[i], y[i])\n",
    "            self.custo += cost\n",
    "        self.custo /= len(x)\n",
    "        return self.custo\n",
    "\n",
    "    def Treinamento(self, x, y, x_Teste, y_Teste, epoca=100):\n",
    "        for i in range(epoca):\n",
    "            self.Teste(x_Teste, y_Teste)\n",
    "            self.BP(x, y)\n",
    "            print('Epoca: {}'.format(i+1))\n",
    "            print('Custo: {}'.format(self.custo))\n",
    "            print(\"/-----------------------------------------------/\")\n",
    "\n",
    "\n",
    "    def Teste(self, x, y):\n",
    "        acuracia = 0\n",
    "        for i in range(len(x)):\n",
    "            saida = self.forward(x[i])[1]\n",
    "            index, _ = max(enumerate(saida), key = operator.itemgetter(1))\n",
    "            if y[i][index] == 1:\n",
    "                acuracia += 1\n",
    "            if acuracia / len(x) > self.maxAcuracia:\n",
    "                self.maxAcuracia = acuracia / len(x)\n",
    "        print('Acuracia: {}'.format(acuracia / len(x)))\n",
    "        \n",
    "    def MaxAcuracia(self):\n",
    "         print('Acuracia maxima: {}'.format(self.maxAcuracia))\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "\n",
    "    @staticmethod\n",
    "    def tanh(x):\n",
    "        return (1-np.exp(-2*x))/(1+np.exp(-2*x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtenção dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_Treinamento, y_Treinamento), (x_Teste, y_Teste) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_Treinamento = x_Treinamento.reshape(60000, 784)\n",
    "x_Teste = x_Teste.reshape(10000, 784)\n",
    "\n",
    "numClasses = 10\n",
    "\n",
    "x_Treinamento = x_Treinamento.astype('float32')\n",
    "x_Teste = x_Teste.astype('float32')\n",
    "x_Treinamento /= 255\n",
    "x_Teste /= 255\n",
    "\n",
    "t_Treinamento = np.zeros((y_Treinamento.shape[0], numClasses))\n",
    "t_Treinamento[np.arange(y_Treinamento.shape[0]), y_Treinamento] = 1\n",
    "y_Treinamento = t_Treinamento\n",
    "\n",
    "t_Teste = np.zeros((y_Teste.shape[0], numClasses))\n",
    "t_Teste[np.arange(y_Teste.shape[0]), y_Teste] = 1\n",
    "y_Teste = t_Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exibição dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia: 0.0875\n",
      "Epoca: 1\n",
      "Custo: 0.0007201606831143412\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.4413\n",
      "Epoca: 2\n",
      "Custo: 0.0005485063423816205\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.6757\n",
      "Epoca: 3\n",
      "Custo: 0.00038466538214368076\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.6863\n",
      "Epoca: 4\n",
      "Custo: 0.0003837534649940763\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.7286\n",
      "Epoca: 5\n",
      "Custo: 0.0003532522897940774\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.7446\n",
      "Epoca: 6\n",
      "Custo: 0.00038536886071745106\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8118\n",
      "Epoca: 7\n",
      "Custo: 0.0002701018009223135\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.7967\n",
      "Epoca: 8\n",
      "Custo: 0.0003121152858698553\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.7937\n",
      "Epoca: 9\n",
      "Custo: 0.0002931647538277691\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.7845\n",
      "Epoca: 10\n",
      "Custo: 0.00028034774532840193\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.7935\n",
      "Epoca: 11\n",
      "Custo: 0.0002808138078320302\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8465\n",
      "Epoca: 12\n",
      "Custo: 0.0002487158111502921\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8331\n",
      "Epoca: 13\n",
      "Custo: 0.00027675901493851647\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8023\n",
      "Epoca: 14\n",
      "Custo: 0.0002532353183481105\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8342\n",
      "Epoca: 15\n",
      "Custo: 0.0002834781113241735\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8419\n",
      "Epoca: 16\n",
      "Custo: 0.00020611031836217664\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8265\n",
      "Epoca: 17\n",
      "Custo: 0.00028501377716346106\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8253\n",
      "Epoca: 18\n",
      "Custo: 0.0002568397245617469\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8467\n",
      "Epoca: 19\n",
      "Custo: 0.00021245008750954842\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8533\n",
      "Epoca: 20\n",
      "Custo: 0.00021073301749731022\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.83\n",
      "Epoca: 21\n",
      "Custo: 0.00026524746966470966\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8185\n",
      "Epoca: 22\n",
      "Custo: 0.00017161968000007415\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8577\n",
      "Epoca: 23\n",
      "Custo: 0.00019811829065065331\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8609\n",
      "Epoca: 24\n",
      "Custo: 0.0002462688901594264\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.853\n",
      "Epoca: 25\n",
      "Custo: 0.00020922771315144876\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8632\n",
      "Epoca: 26\n",
      "Custo: 0.00021078724750755846\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8642\n",
      "Epoca: 27\n",
      "Custo: 0.00023600407666189967\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8739\n",
      "Epoca: 28\n",
      "Custo: 0.0002541989176600081\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8656\n",
      "Epoca: 29\n",
      "Custo: 0.00019567284045541312\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8572\n",
      "Epoca: 30\n",
      "Custo: 0.00024257784061523704\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8615\n",
      "Epoca: 31\n",
      "Custo: 0.0002780522758019622\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8639\n",
      "Epoca: 32\n",
      "Custo: 0.00016001912789311606\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8291\n",
      "Epoca: 33\n",
      "Custo: 0.0001816552046771891\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8642\n",
      "Epoca: 34\n",
      "Custo: 0.00015239226469776048\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8597\n",
      "Epoca: 35\n",
      "Custo: 0.00019658544775396673\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8812\n",
      "Epoca: 36\n",
      "Custo: 0.00018560747437557432\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8483\n",
      "Epoca: 37\n",
      "Custo: 0.00018140012929935466\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8634\n",
      "Epoca: 38\n",
      "Custo: 0.00025021920252963324\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8692\n",
      "Epoca: 39\n",
      "Custo: 0.00021297753857458526\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8716\n",
      "Epoca: 40\n",
      "Custo: 0.0002095319653903448\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.865\n",
      "Epoca: 41\n",
      "Custo: 0.00019141494438440853\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8682\n",
      "Epoca: 42\n",
      "Custo: 0.0002624251789512415\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8578\n",
      "Epoca: 43\n",
      "Custo: 0.0001794945504979879\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8836\n",
      "Epoca: 44\n",
      "Custo: 0.00013915206002760954\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8893\n",
      "Epoca: 45\n",
      "Custo: 0.00022889536166690772\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.882\n",
      "Epoca: 46\n",
      "Custo: 0.0001936897016464265\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8494\n",
      "Epoca: 47\n",
      "Custo: 0.000158702473343177\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8864\n",
      "Epoca: 48\n",
      "Custo: 0.00011272251483614006\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8838\n",
      "Epoca: 49\n",
      "Custo: 0.0001750380392625124\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8871\n",
      "Epoca: 50\n",
      "Custo: 0.00022606791929328152\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8832\n",
      "Epoca: 51\n",
      "Custo: 0.00022554025758737551\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8625\n",
      "Epoca: 52\n",
      "Custo: 0.00020116334575775763\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8594\n",
      "Epoca: 53\n",
      "Custo: 0.00015801992734101815\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8614\n",
      "Epoca: 54\n",
      "Custo: 0.0002449646821261493\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8743\n",
      "Epoca: 55\n",
      "Custo: 0.00015816313809892426\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8813\n",
      "Epoca: 56\n",
      "Custo: 0.00013835743730323703\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8906\n",
      "Epoca: 57\n",
      "Custo: 0.00018886616429921875\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8406\n",
      "Epoca: 58\n",
      "Custo: 0.00015741095601976932\n",
      "/-----------------------------------------------/\n",
      "Acuracia: 0.8743\n",
      "Epoca: 59\n",
      "Custo: 0.00013149530498964696\n",
      "/-----------------------------------------------/\n"
     ]
    }
   ],
   "source": [
    "N_HIDEN_LAYER = 397\n",
    "BP_Model = BP_Model(784, N_HIDEN_LAYER, numClasses)\n",
    "BP_Model.Treinamento(x_Treinamento, y_Treinamento, x_Teste, y_Teste)\n",
    "BP_Model.MaxAcuracia()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
