{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho - Redes Neurais Artificiais\n",
    "\n",
    "## Método adotado: Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rafael Maia e Luís "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação das bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BP_Model:\n",
    "    maxAcuracia = 0 \n",
    "    def __init__(self, tamEntrada, tamCamadaEscondida, tamSaida, rate=0.1):\n",
    "        self.dEntrada = tamEntrada\n",
    "        self.dCamadaEscondida = tamCamadaEscondida\n",
    "        self.dSaida = tamSaida\n",
    "        self.wInH = np.random.rand(self.dEntrada, self.dCamadaEscondida)*0.2-0.1\n",
    "        self.wOutH = np.random.rand(self.dCamadaEscondida, self.dSaida)*0.2-0.1\n",
    "        self.delta_InH = np.zeros(self.dCamadaEscondida)\n",
    "        self.delta_OutH = np.zeros(self.dSaida)\n",
    "        self.learning_rate = rate\n",
    "        self.custo = 0\n",
    "\n",
    "    def forward(self, sample):\n",
    "        ativCamadaOculta = self.tanh(np.dot(sample, self.wInH))\n",
    "        activCamadaSaida = self.sigmoid(np.dot(ativCamadaOculta, self.wOutH))\n",
    "        return ativCamadaOculta, activCamadaSaida\n",
    "\n",
    "    def auxAcao(self, x, y):\n",
    "        saida = self.forward(x)[1]\n",
    "        return np.sum((np.array(saida) - np.array(y))**2)*0.5, np.array(saida)-np.array(y)\n",
    "\n",
    "    def Acao(self, x, y):\n",
    "        val = 0.\n",
    "        vec = np.zeros(self.dSaida)\n",
    "        for i in range(len(x)):\n",
    "            temp = self.auxAcao(x[i],y[i])\n",
    "            val += temp[0]\n",
    "            vec += temp[1]\n",
    "        return val, vec\n",
    "\n",
    "    def auxBP(self, x, y):\n",
    "        custo, custo_vec = self.auxAcao(x, y)\n",
    "        activHidden, activSaida = self.forward(x)\n",
    "        deltaSaida = custo_vec * activSaida * (1-activSaida)\n",
    "        deltaH = np.dot(self.wOutH, deltaSaida) * (1-activHidden**2)\n",
    "        self.wOutH -= self.learning_rate*deltaSaida*activHidden[:,np.newaxis]\n",
    "        self.wInH -= self.learning_rate * deltaH * np.array(x)[:,np.newaxis]\n",
    "        return self.wOutH, self.wInH, custo\n",
    "\n",
    "    def BP(self, x, y):\n",
    "        self.custo = 0\n",
    "        tam = np.arange(len(x))\n",
    "        np.random.shuffle(tam)\n",
    "        for i in tam[:100]:\n",
    "            wOutH, wInH, cost = self.auxBP(x[i], y[i])\n",
    "            self.custo += cost\n",
    "        self.custo /= len(x)\n",
    "        return self.custo\n",
    "\n",
    "    def Treinamento(self, x, y, x_Teste, y_Teste, epoca=100):\n",
    "        for i in range(epoca):\n",
    "            self.Teste(x_Teste, y_Teste)\n",
    "            self.BP(x, y)\n",
    "            print('Epoca: {}'.format(i+1))\n",
    "            print('Custo: {}'.format(self.custo))\n",
    "            print(\"/-----------------------------------------------/\")\n",
    "\n",
    "\n",
    "    def Teste(self, x, y):\n",
    "        acuracia = 0\n",
    "        for i in range(len(x)):\n",
    "            saida = self.forward(x[i])[1]\n",
    "            index, _ = max(enumerate(saida), key = operator.itemgetter(1))\n",
    "            if y[i][index] == 1:\n",
    "                acuracia += 1\n",
    "            if acuracia / len(x) > self.maxAcuracia:\n",
    "                self.maxAcuracia = acuracia / len(x)\n",
    "        print('Acuracia: {}'.format(acuracia / len(x)))\n",
    "        \n",
    "    def MaxAcuracia(self):\n",
    "         print('Acuracia maxima: {}'.format(self.maxAcuracia))\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "\n",
    "    @staticmethod\n",
    "    def tanh(x):\n",
    "        return (1-np.exp(-2*x))/(1+np.exp(-2*x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtenção dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_Treinamento, y_Treinamento), (x_Teste, y_Teste) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_Treinamento = x_Treinamento.reshape(60000, 784)\n",
    "x_Teste = x_Teste.reshape(10000, 784)\n",
    "\n",
    "numClasses = 10\n",
    "\n",
    "x_Treinamento = x_Treinamento.astype('float32')\n",
    "x_Teste = x_Teste.astype('float32')\n",
    "x_Treinamento /= 255\n",
    "x_Teste /= 255\n",
    "\n",
    "t_Treinamento = np.zeros((y_Treinamento.shape[0], numClasses))\n",
    "t_Treinamento[np.arange(y_Treinamento.shape[0]), y_Treinamento] = 1\n",
    "y_Treinamento = t_Treinamento\n",
    "\n",
    "t_Teste = np.zeros((y_Teste.shape[0], numClasses))\n",
    "t_Teste[np.arange(y_Teste.shape[0]), y_Teste] = 1\n",
    "y_Teste = t_Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição da camada escondida\n",
    "O número de neurônios em cada camada é uma questão mais empírica, não existindo regras explícitas para um cálculo ideal. Jeff Heaton, o autor de <b><i>Introduction to Neural Networks for Java</i></b>, sugere três abordagens iniciais, que vamos aplicar como exemplo para uma rede contendo 30 neurônios na camada de entrada e 2 neurônios na camada de saída:\n",
    "\n",
    "* O número de neurônios escondidos deve estar entre o tamanho da camada de entrada e o da camada de saída. Usar o número médio entre as duas camadas é uma boa opção; ou seja, no nosso exemplo, o valor de (30+2)/2 = 16 neurônios.\n",
    "* O número de neurônios escondidos deve ser 2/3 do tamanho da camada de entrada, mais o tamanho da camada de saída. Assim, a camada escondida no nosso exemplo deve conter 30*2/3+2 = 22 neurônios.\n",
    "* O número de neurônios escondidos deve ser menor que o dobro do tamanho da camada de entrada. Ou seja, no nosso exemplo, a camada escondida deve conter menos que 60 neurônios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_HIDEN_LAYER = 397"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exibição dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'BP_Model' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8d66392c6cb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mBP_Model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBP_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_HIDEN_LAYER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumClasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mBP_Model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTreinamento\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_Treinamento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_Treinamento\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_Teste\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_Teste\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mBP_Model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxAcuracia\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'BP_Model' object is not callable"
     ]
    }
   ],
   "source": [
    "BP_Model = BP_Model(784, N_HIDEN_LAYER, numClasses)\n",
    "BP_Model.Treinamento(x_Treinamento, y_Treinamento, x_Teste, y_Teste)\n",
    "BP_Model.MaxAcuracia()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
